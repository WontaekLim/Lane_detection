{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the camera calibration matrix and distortion coefficients from chessboard iamges\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "def camCalibration():\n",
    "    # Prepare object points\n",
    "    objp = np.zeros( (6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    " \n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "        \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    \n",
    "    return ret, mtx, dist\n",
    "\n",
    "# Apply a distortion correction to raw images\n",
    "def undistortImg( img, mtx, dist ):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "def abs_sobel_thresh(gray, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))        \n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))    \n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    \n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Color space\n",
    "def hls_select_s(img, thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "#     binary_output = np.zeros_like(s_channel)\n",
    "#     binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    binary_output = s_channel\n",
    "    return binary_output\n",
    "\n",
    "def hls_select_h(img, thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,1]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1   \n",
    "    return binary_output\n",
    "\n",
    "# Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "def convBirdEyeView(img, src, dst ):\n",
    "#     img_size = (img.shape[1], img.shape[0])\n",
    "    img_size = (480, 720)\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    wrap_img = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return wrap_img, Minv\n",
    "\n",
    "# Detect lane pixels and fit to find the lane boundary.\n",
    "def findLane(img, bCRegion = False ):\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 15\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    dist = list( range(int(img.shape[0]/2), img.shape[0]))    \n",
    "    histogram = np.dot( dist, img[img.shape[0]/2:,:])  \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))  * 255  \n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 45\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 20\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    if bCRegion == True:\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)        \n",
    "\n",
    "    # Calculate a curvature\n",
    "    y_eval = 0\n",
    "    \n",
    "    ym_per_pix = 30/720\n",
    "    xm_per_pix = 3.7/310\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space    \n",
    "    fit_cr_left = np.polyfit(ploty*ym_per_pix, (left_fitx[::-1])*xm_per_pix, 2)\n",
    "    fit_cr_right = np.polyfit(ploty*ym_per_pix, (right_fitx[::-1])*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    curverad_left = ((1 + (2*fit_cr_left[0]*y_eval*ym_per_pix + fit_cr_left[1])**2)**1.5) / np.absolute(2*fit_cr_left[0])\n",
    "    curverad_right = ((1 + (2*fit_cr_right[0]*y_eval*ym_per_pix + fit_cr_right[1])**2)**1.5) / np.absolute(2*fit_cr_right[0])\n",
    "    \n",
    "    \n",
    "    # Offset\n",
    "    pos_left = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]\n",
    "    pos_right = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]    \n",
    "    midpoint = (pos_left + pos_right)/2\n",
    "    offset = (midpoint - img.shape[1]/2)\n",
    "    offset_m = offset * xm_per_pix\n",
    "    \n",
    "    \n",
    "    # Draw     \n",
    "    pts_l = np.transpose( np.vstack( [left_fitx, ploty] ) )\n",
    "    pts_r = np.transpose( np.vstack( [right_fitx, ploty] ) )    \n",
    "    cv2.polylines( out_img, np.int_([pts_l]), 0, (0,255,0), thickness=3)\n",
    "    cv2.polylines( out_img, np.int_([pts_r]), 0, (0,255,0), thickness=3)\n",
    "    \n",
    "    return out_img, ploty, left_fitx, right_fitx, curverad_left, curverad_right, offset_m\n",
    "\n",
    "# Determine the curvature of the lane and vehicle position with respect to center.\n",
    "class LIne():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self. detected = False\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        # average x values of the fitted line over the last \n",
    "        self.bestx = None\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        #radius of curvature of the line in som units\n",
    "        self.radius_of_curvature = None\n",
    "        #distance in meters of vehicle center frme the line\n",
    "        self.line_base_pos = None\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')\n",
    "        #x values for detected ine pixels\n",
    "        self.allx = None\n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        \n",
    "# Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "def drawResult( undist, Minv, warped, ploty, left_fitx, right_fitx ):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fill\n",
    "    pts_left = np.array( [np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array( [np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack( (pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly( color_warp, np.int_([pts]), (0,255,0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective( color_warp, Minv, (undist.shape[1], undist.shape[0]))\n",
    "    # Combine the result with the orginal image\n",
    "    result = cv2.addWeighted( undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lanefilter(img, \n",
    "                 Ksizex, threshx, \n",
    "                 Ksizey, threshy, \n",
    "                 Ksize_mag, thresh_mag, \n",
    "                 ksize_dir, thresh_dir):\n",
    "    \n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=Ksizex, thresh=(threshx[0], threshx[1]) )\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=Ksizey, thresh=(threshy[0], threshy[1]) )\n",
    "    mag = mag_thresh(img, sobel_kernel=Ksize_mag, mag_thresh=(thresh_mag[0], thresh_mag[1]))\n",
    "    dir = dir_threshold(img, sobel_kernel=ksize_dir, thresh=(thresh_dir[0], thresh_dir[1]))\n",
    "    \n",
    "    combined_sobel = np.zeros_like(img)\n",
    "    combined_dir = np.zeros_like(img)\n",
    "    combined = np.zeros_like(img)    \n",
    "    \n",
    "    combined_sobel[(gradx == 1) | (grady == 1) ] =1\n",
    "    combined_dir[(mag == 1) & (dir == 1) ] =1    \n",
    "    combined[(combined_sobel==1)| (combined_dir==1)] =1\n",
    "    \n",
    "    return combined_sobel, combined_dir, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lanefilter_angle(img, \n",
    "                 Ksizex, threshx, \n",
    "                 Ksizey, threshy,                  \n",
    "                 ksize_dir, thresh_dir):\n",
    "    \n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=Ksizex, thresh=(threshx[0], threshx[1]) )\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=Ksizey, thresh=(threshy[0], threshy[1]) )    \n",
    "    dir = dir_threshold(img, sobel_kernel=ksize_dir, thresh=(thresh_dir[0], thresh_dir[1]))\n",
    "    \n",
    "    combined_sobel = np.zeros_like(img)\n",
    "    combined_dir = dir\n",
    "    combined = np.zeros_like(img)    \n",
    "    \n",
    "    combined_sobel[(gradx == 1) | (grady == 1) ] =1\n",
    "    combined[(combined_sobel==1)& (combined_dir==1)] =1\n",
    "    \n",
    "    return combined_sobel, combined_dir, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(img, bPlot = False):\n",
    "    \n",
    "    # 2. Processing\n",
    "    # 2.1 Undistortion\n",
    "    undis_img = undistortImg( img, mtx, dist )\n",
    "    \n",
    "    # 2.2 Filtering using gradient (sobel)\n",
    "    img_hls =  cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    gray = undis_img[:,:,0]\n",
    "    \n",
    "    img_r = undis_img[:,:,0]\n",
    "    img_g = undis_img[:,:,1]\n",
    "    img_b = undis_img[:,:,2]\n",
    "    \n",
    "    img_s = img_hls[:,:,2]\n",
    "    img_h = img_hls[:,:,0]\n",
    "    img_l = img_hls[:,:,1]\n",
    "    \n",
    "    \n",
    "    combined_sobel_g, combined_dir_g, combined_g = lanefilter_angle(gray, \n",
    "                                                             Ksizex=15, threshx=(5,255), \n",
    "                                                             Ksizey=15, threshy=(50,255),                                                              \n",
    "                                                             ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    \n",
    "    combined_sobel_s, combined_dir_s, combined_s = lanefilter(img_s, \n",
    "                                                             Ksizex=15, threshx=(30,255), \n",
    "                                                             Ksizey=15, threshy=(80,255), \n",
    "                                                             Ksize_mag=15, thresh_mag=(40,255), \n",
    "                                                             ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    \n",
    "    combined_sobel_l, combined_dir_l, combined_l = lanefilter_angle(img_l, \n",
    "                                                         Ksizex=15, threshx=(10,255), \n",
    "                                                         Ksizey=15, threshy=(30,255),                                                          \n",
    "                                                         ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    img_test = np.zeros_like(img_l)\n",
    "    img_test[(img_h > 100)] = 1 \n",
    "        \n",
    "    combined = np.zeros_like(gray)\n",
    "    combined[ (combined_g==1) | (combined_s==1) ] = 1\n",
    "\n",
    "    \n",
    "    offset_x = 100\n",
    "    offset_y = 100\n",
    "\n",
    "    #Video 1: project.mp4\n",
    "#     yframe = 450\n",
    "#     xframe_ls = 265\n",
    "#     xframe_rs = 1050\n",
    "#     xframe_ll = 595\n",
    "#     xframe_rl = 685\n",
    "        \n",
    "#     perImgSize_w = 480\n",
    "#     perImgSize_h = 720\n",
    "    \n",
    "\n",
    "    #Video 2: challenge.mp4\n",
    "    yframe = 480\n",
    "    xframe_ls = 300\n",
    "    xframe_rs = 958    \n",
    "    xframe_ll = 600\n",
    "    xframe_rl = 718\n",
    "        \n",
    "    perImgSize_w = 480\n",
    "    perImgSize_h = 720\n",
    "\n",
    "    src = np.float32( [[xframe_ll, yframe], [xframe_rl, yframe], [xframe_rs, 680], [xframe_ls, 680]] )\n",
    "    dst = np.float32( [[offset_x,0], [perImgSize_w-offset_x,0], [perImgSize_w-offset_x,perImgSize_h], [offset_x, perImgSize_h]])\n",
    "    perImg, Minv = convBirdEyeView( combined, src, dst )    \n",
    "    \n",
    "    out, ploty, Lfit, Rfit, Curature_left, Curature_right, offset_m = findLane(perImg)\n",
    "    \n",
    "    result = drawResult(undis_img, Minv, perImg, ploty, Lfit, Rfit)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText( result, \"Radius Left [m]: \" + str(Curature_left), (70, 100),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Radius Right[m]: \" + str(Curature_right), (70, 150),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Offset [m]: \" + str(offset_m), (70, 200),font, 1, (255,0,0), 2, cv2.LINE_AA )\n",
    "\n",
    "    test_img = img\n",
    "    test_img_per = out\n",
    "    \n",
    "    cv2.polylines(test_img, np.int32([src]), 30, (255,0,0))\n",
    "    cv2.polylines(test_img_per, np.int32([dst]), 30, (255,255,255))\n",
    "    \n",
    "    plt.figure(10)\n",
    "    plt.imshow(test_img)\n",
    "    plt.figure(11)\n",
    "    plt.imshow(test_img_per)\n",
    "    \n",
    "    if bPlot == True:\n",
    "        # plot images\n",
    "        plt.figure(1)\n",
    "        plt.rcParams[\"figure.figsize\"] = [10, 14]\n",
    "\n",
    "        ax1 = plt.subplot2grid( (4,3), (0,0) )\n",
    "        ax1.imshow( combined_sobel_g , cmap='gray')\n",
    "        ax1.set_title('combined_sobel_g', fontsize=10)\n",
    "\n",
    "        ax2 = plt.subplot2grid( (4,3), (0,1) )\n",
    "        ax2.imshow( combined_dir_g , cmap='gray' )\n",
    "        ax2.set_title('combined_dir_g', fontsize=10)\n",
    "\n",
    "        ax3 = plt.subplot2grid( (4,3), (0,2) )\n",
    "        ax3.imshow( combined_g , cmap='gray' )\n",
    "        ax3.set_title('combined_g', fontsize=10)\n",
    "\n",
    "        ax4 = plt.subplot2grid( (4,3), (1,0) )\n",
    "        ax4.imshow( combined_sobel_s, cmap='gray' )\n",
    "        ax4.set_title('combined_sobel_s', fontsize=10)\n",
    "\n",
    "        ax5 = plt.subplot2grid( (4,3), (1,1) )\n",
    "        ax5.imshow( combined_dir_s, cmap='gray' )\n",
    "        ax5.set_title('combined_dir_s', fontsize=10)\n",
    "\n",
    "        ax6 = plt.subplot2grid( (4,3), (1,2) )\n",
    "        ax6.imshow( combined_s, cmap='gray' )\n",
    "        ax6.set_title('combined_s', fontsize=10)\n",
    "\n",
    "        ax7 = plt.subplot2grid( (4,3), (2,0) )\n",
    "        ax7.imshow( combined_sobel_l, cmap='gray' )\n",
    "        ax7.set_title('combined_sobel_l', fontsize=10)\n",
    "\n",
    "        ax8 = plt.subplot2grid( (4,3), (2,1) )\n",
    "        ax8.imshow( combined_dir_l, cmap='gray' )\n",
    "        ax8.set_title('combined_dir_l', fontsize=10)\n",
    "\n",
    "        ax9 = plt.subplot2grid( (4,3), (2,2) )\n",
    "        ax9.imshow( combined_l, cmap='gray' )\n",
    "        ax9.set_title('combined_l', fontsize=10)\n",
    "\n",
    "        ax10 = plt.subplot2grid( (4,3), (3,0) )\n",
    "        ax10.imshow( combined, cmap='gray' )\n",
    "        ax10.set_title('Combined', fontsize=10)\n",
    "\n",
    "        ax11 = plt.subplot2grid( (4,3), (3,1) )\n",
    "        ax11.imshow( out )\n",
    "        ax11.set_title('Output', fontsize=10)\n",
    "\n",
    "        ax12 = plt.subplot2grid( (4,3), (3,2) )\n",
    "        ax12.imshow( result )\n",
    "        ax12.set_title('result', fontsize=10)\n",
    "\n",
    "        plt.subplots_adjust( left = 0, right = 1, top = 0.9, bottom=0.)\n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibration from chessboard images\n",
    "ret, mtx, dist = camCalibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the undistorted image (example)\n",
    "chess_img_file = './camera_cal/calibration1.jpg'\n",
    "chess_img = cv2.imread(chess_img_file)\n",
    "\n",
    "chess_undis = undistortImg( chess_img, mtx, dist)\n",
    "\n",
    "cv2.imwrite(\"./writeup_image/distorted image.jpg\", chess_img)\n",
    "cv2.imwrite(\"./writeup_image/undistorted image.jpg\", chess_undis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lim\\Anaconda3\\envs\\udacity\\lib\\site-packages\\ipykernel\\__main__.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for fname in images:    \n",
    "# fname = './test_images/test1.jpg'\n",
    "\n",
    "    # 1. Load a test image\n",
    "    img = cv2.imread(fname)\n",
    "#     result_img = process_image(img, True)\n",
    "\n",
    "    # 2. Pipeline for lane finding\n",
    "\n",
    "    ## 2.1 Undistortion\n",
    "    undis_img = undistortImg( img, mtx, dist )\n",
    "\n",
    "\n",
    "    ## 2.2 Image filtering    \n",
    "    # Color channel: R channel, S channel\n",
    "    gray = undis_img[:,:,1]\n",
    "    img_hls =  cv2.cvtColor(undis_img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    gray = undis_img[:,:,1] # Gray(R channel)\n",
    "    img_s = img_hls[:,:,2] # S channel\n",
    "\n",
    "    # Sobel filter of R and S channel, respectively\n",
    "    combined_sobel_g, combined_dir_g, combined_g = lanefilter(gray, \n",
    "                                                             Ksizex=15, threshx=(30,255), \n",
    "                                                             Ksizey=15, threshy=(80,255), \n",
    "                                                             Ksize_mag=15, thresh_mag=(40,255), \n",
    "                                                             ksize_dir=15, thresh_dir=(0.7, 1.3))\n",
    "\n",
    "    combined_sobel_s, combined_dir_s, combined_s = lanefilter(img_s, \n",
    "                                                             Ksizex=15, threshx=(30,255), \n",
    "                                                             Ksizey=15, threshy=(80,255), \n",
    "                                                             Ksize_mag=15, thresh_mag=(40,255), \n",
    "                                                             ksize_dir=15, thresh_dir=(0.7, 1.1))\n",
    "\n",
    "    combined = np.zeros_like(gray)\n",
    "    combined[ (combined_g==1) | (combined_s==1) ] = 1\n",
    "\n",
    "\n",
    "    ## 2.3 Perspective transform\n",
    "    offset_x = 100\n",
    "    offset_y = 100\n",
    "\n",
    "    yframe = 450\n",
    "    xframe_ls = 265\n",
    "    xframe_rs = 1050\n",
    "    xframe_ll = 595\n",
    "    xframe_rl = 685\n",
    "\n",
    "    perImgSize_w = 480\n",
    "    perImgSize_h = 720\n",
    "\n",
    "    src = np.float32( [[xframe_ll, yframe], [xframe_rl, yframe], [xframe_rs, 680], [xframe_ls, 680]] )\n",
    "    dst = np.float32( [[offset_x,0], [perImgSize_w-offset_x,0], [perImgSize_w-offset_x,perImgSize_h], [offset_x, perImgSize_h]])\n",
    "    perImg, Minv = convBirdEyeView( combined, src, dst )    \n",
    "\n",
    "    ## 2.4 Find lanes in a test image\n",
    "    ## ( with Calculate the radius of curvature of lane and the position of the vehicle )\n",
    "    out, ploty, Lfit, Rfit, Curature_left,  Curature_right, offset_m = findLane(perImg)\n",
    "\n",
    "    ## 2.5 Result\n",
    "    result = drawResult(undis_img, Minv, perImg, ploty, Lfit, Rfit)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText( result, \"Radius Left [m]: \" + str(Curature_left), (70, 100),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Radius Right[m]: \" + str(Curature_right), (70, 150),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Offset [m]: \" + str(offset_m), (70, 200),font, 1, (255,0,0), 2, cv2.LINE_AA )\n",
    "\n",
    "\n",
    "    # 3. Result save\n",
    "    foldname = fname[0:14] +  fname[14:int(len(fname)-4)] + fname[13]\n",
    "    isFolder = os.path.isdir(foldname)\n",
    "\n",
    "    if isFolder == False:\n",
    "        os.mkdir(foldname)    \n",
    "\n",
    "    cv2.imwrite(foldname + '1_raw_img.jpg' , img )\n",
    "    cv2.imwrite(foldname + '2_undistortion.jpg' , undis_img )\n",
    "    cv2.imwrite(foldname + '3_filter_r.jpg' , combined_g*255)\n",
    "    cv2.imwrite(foldname + '4_filter_s.jpg' , combined_s*255)\n",
    "    cv2.imwrite(foldname + '5_combined.jpg' , combined*255)\n",
    "    cv2.imwrite(foldname + '6_perspective.jpg' , perImg*255 )\n",
    "    cv2.imwrite(foldname + '7_lanefinding.jpg' , out )\n",
    "    cv2.imwrite(foldname + '8_result.jpg' , result )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lim\\Anaconda3\\envs\\udacity\\lib\\site-packages\\skimage\\filter\\__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n",
      "C:\\Users\\Lim\\Anaconda3\\envs\\udacity\\lib\\site-packages\\moviepy\\audio\\io\\readers.py:110: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.nchannels))\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = \"challenge_video.mp4\"\n",
    "\n",
    "video_output = './test_video/result_' + filename\n",
    "clip = VideoFileClip( \"./test_video/\" + filename )\n",
    "\n",
    "# output_clip = clip.fl_image( process_image )\n",
    "# %time output_clip.write_videofile(video_output, audio=False)\n",
    "# del clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = 13\n",
    "Challenge_image = clip.get_frame(time)\n",
    "cv2.imwrite(\"./chanllenge_images/challenge_\" + str(time) + \".jpg\",  cv2.cvtColor(Challenge_image, cv2.COLOR_RGB2BGR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lim\\Anaconda3\\envs\\udacity\\lib\\site-packages\\ipykernel\\__main__.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images = glob.glob('./chanllenge_images/*.jpg')\n",
    "\n",
    "for fname in images:    \n",
    "# fname = './test_images/test1.jpg'\n",
    "\n",
    "    # 1. Load a test image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "\n",
    "    # 2. Pipeline for lane finding\n",
    "    ## 2.1 Undistortion\n",
    "    undis_img = undistortImg( img, mtx, dist )\n",
    "\n",
    "    # 2.2 Filtering using gradient (sobel)\n",
    "    img_hls =  cv2.cvtColor(undis_img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    gray = undis_img[:,:,0]\n",
    "    \n",
    "    img_r = undis_img[:,:,0]\n",
    "    img_g = undis_img[:,:,1]\n",
    "    img_b = undis_img[:,:,2]\n",
    "    \n",
    "    img_s = img_hls[:,:,2]\n",
    "    img_h = img_hls[:,:,0]\n",
    "    img_l = img_hls[:,:,1]\n",
    "        \n",
    "    \n",
    "    combined_sobel_g, combined_dir_g, combined_g = lanefilter_angle(gray, \n",
    "                                                             Ksizex=15, threshx=(5,255), \n",
    "                                                             Ksizey=15, threshy=(50,255),                                                              \n",
    "                                                             ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    \n",
    "    combined_sobel_s, combined_dir_s, combined_s = lanefilter(img_s, \n",
    "                                                             Ksizex=15, threshx=(30,255), \n",
    "                                                             Ksizey=15, threshy=(80,255), \n",
    "                                                             Ksize_mag=15, thresh_mag=(40,255), \n",
    "                                                             ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    \n",
    "    combined_sobel_l, combined_dir_l, combined_l = lanefilter_angle(img_l, \n",
    "                                                         Ksizex=15, threshx=(10,255), \n",
    "                                                         Ksizey=15, threshy=(30,255),                                                          \n",
    "                                                         ksize_dir=15, thresh_dir=(0.8, 1.4))\n",
    "    img_test = np.zeros_like(img_l)\n",
    "    img_test[(img_h > 100)] = 1 \n",
    "        \n",
    "    combined = np.zeros_like(gray)\n",
    "    combined[ (combined_g==1) | (combined_s==1) ] = 1\n",
    "\n",
    "\n",
    "    ## 2.3 Perspective transform\n",
    "    offset_x = 100\n",
    "    offset_y = 100\n",
    "\n",
    "    yframe = 480\n",
    "    xframe_ls = 300\n",
    "    xframe_rs = 958    \n",
    "    xframe_ll = 600\n",
    "    xframe_rl = 718\n",
    "        \n",
    "    perImgSize_w = 480\n",
    "    perImgSize_h = 720\n",
    "\n",
    "    src = np.float32( [[xframe_ll, yframe], [xframe_rl, yframe], [xframe_rs, 680], [xframe_ls, 680]] )\n",
    "    dst = np.float32( [[offset_x,0], [perImgSize_w-offset_x,0], [perImgSize_w-offset_x,perImgSize_h], [offset_x, perImgSize_h]])\n",
    "    perImg, Minv = convBirdEyeView( combined, src, dst )    \n",
    "\n",
    "    ## 2.4 Find lanes in a test image\n",
    "    ## ( with Calculate the radius of curvature of lane and the position of the vehicle )\n",
    "    out, ploty, Lfit, Rfit, Curature_left,  Curature_right, offset_m = findLane(perImg)\n",
    "\n",
    "    ## 2.5 Result\n",
    "    result = drawResult(undis_img, Minv, perImg, ploty, Lfit, Rfit)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText( result, \"Radius Left [m]: \" + str(Curature_left), (70, 100),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Radius Right[m]: \" + str(Curature_right), (70, 150),font, 1, (255,0,0), 2, cv2.LINE_AA )    \n",
    "    cv2.putText( result, \"Offset [m]: \" + str(offset_m), (70, 200),font, 1, (255,0,0), 2, cv2.LINE_AA )\n",
    "\n",
    "\n",
    "    # 3. Result save\n",
    "    foldname = fname[0:19] +  fname[19:int(len(fname)-4)] + fname[19]\n",
    "    isFolder = os.path.isdir(foldname)\n",
    "\n",
    "    if isFolder == False:\n",
    "        os.mkdir(foldname)    \n",
    "\n",
    "    cv2.imwrite(foldname + '1_raw_img.jpg' , img )\n",
    "    cv2.imwrite(foldname + '2_undistortion.jpg' , undis_img )\n",
    "    cv2.imwrite(foldname + '3_filter_r.jpg' , combined_g*255)\n",
    "    cv2.imwrite(foldname + '4_filter_s.jpg' , combined_s*255)\n",
    "    cv2.imwrite(foldname + '5_combined.jpg' , combined*255)\n",
    "    cv2.imwrite(foldname + '6_perspective.jpg' , perImg*255 )\n",
    "    cv2.imwrite(foldname + '7_lanefinding.jpg' , out )\n",
    "    cv2.imwrite(foldname + '8_result.jpg' , result_img )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
